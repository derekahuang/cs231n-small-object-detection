{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import csv\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pickle\n",
    "\n",
    "\n",
    "from scoring.score import score, convert_to_rectangle_list\n",
    "from scoring.matching import Matching\n",
    "from scoring.rectangle import Rectangle\n",
    "from utils.utils import plot_one_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all ground truth bboxes\n",
    "mat = scipy.io.loadmat('scoring/ground_truth.mat')\n",
    "gt_coords, gt_chips, gt_classes = mat['gt_coords'], mat['gt_chips'], mat['gt_classes']\n",
    "gt_unique = np.unique(gt_classes.astype(np.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{11: 'Fixed-wing Aircraft', 12: 'Small Aircraft', 13: 'Cargo Plane', 15: 'Helicopter', 17: 'Passenger Vehicle', 18: 'Small Car', 19: 'Bus', 20: 'Pickup Truck', 21: 'Utility Truck', 23: 'Truck', 24: 'Cargo Truck', 25: 'Truck w/Box', 26: 'Truck Tractor', 27: 'Trailer', 28: 'Truck w/Flatbed', 29: 'Truck w/Liquid', 32: 'Crane Truck', 33: 'Railway Vehicle', 34: 'Passenger Car', 35: 'Cargo Car', 36: 'Flat Car', 37: 'Tank car', 38: 'Locomotive', 40: 'Maritime Vessel', 41: 'Motorboat', 42: 'Sailboat', 44: 'Tugboat', 45: 'Barge', 47: 'Fishing Vessel', 49: 'Ferry', 50: 'Yacht', 51: 'Container Ship', 52: 'Oil Tanker', 53: 'Engineering Vehicle', 54: 'Tower crane', 55: 'Container Crane', 56: 'Reach Stacker', 57: 'Straddle Carrier', 59: 'Mobile Crane', 60: 'Dump Truck', 61: 'Haul Truck', 62: 'Scraper/Tractor', 63: 'Front loader/Bulldozer', 64: 'Excavator', 65: 'Cement Mixer', 66: 'Ground Grader', 71: 'Hut/Tent', 72: 'Shed', 73: 'Building', 74: 'Aircraft Hangar', 76: 'Damaged Building', 77: 'Facility', 79: 'Construction Site', 83: 'Vehicle Lot', 84: 'Helipad', 86: 'Storage Tank', 89: 'Shipping container lot', 91: 'Shipping Container', 93: 'Pylon', 94: 'Tower'}\n"
     ]
    }
   ],
   "source": [
    "# Get class number to name mappings\n",
    "class_nums = [ 11.0, 12.0, 13.0, 15.0, 17.0, 18.0, 19.0, 20.0, 21.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 40.0, 41.0, 42.0, 44.0, 45.0, 47.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 71.0, 72.0, 73.0, 74.0, 76.0, 77.0, 79.0, 83.0, 84.0, 86.0, 89.0, 91.0, 93.0, 94.0]\n",
    "with open('data/xview.names') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "class_num_to_name = { int(c): lines[i].strip() for i, c in enumerate(class_nums) }\n",
    "print(class_num_to_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get stats from an image\n",
    "Adapted from scoring/score.py, `score` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = ''#'_ed_area_lcls_n1024_b25_x100_continuous'\n",
    "output_folder = 'output' + suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detections(img_filename):\n",
    "    path = './' + output_folder + '/' + img_filename + '.txt'\n",
    "    \n",
    "    with open(path, 'r') as f:\n",
    "        arr = np.array(list(csv.reader(f, delimiter=\" \")))\n",
    "        assert arr.shape[0] != 0 # make sure file isn't empty\n",
    "        \n",
    "        arr = arr[:, :6].astype(np.float64)\n",
    "        threshold = 0\n",
    "        arr = arr[arr[:, 5] > threshold] # Claire comment: confidence threshold (currently 0)\n",
    "        det_classes = list(arr[:, 4])\n",
    "        num_preds = arr.shape[0]\n",
    "\n",
    "        if np.any(arr[:, :4] < 0):\n",
    "            raise ValueError('Bounding boxes cannot be negative.')\n",
    "\n",
    "        if np.any(arr[:, 5] < 0) or np.any(arr[:, 5] > 1):\n",
    "            raise ValueError('Confidence scores should be between 0 and 1.')\n",
    "            \n",
    "        det_box = arr[:, :4]\n",
    "        det_scores = arr[:, 5]\n",
    "        det_cls = arr[:, 4]\n",
    "    \n",
    "    return det_box, det_scores, det_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_one(img_filename, iou_threshold=.5):\n",
    "    assert (iou_threshold < 1 and iou_threshold > 0)\n",
    "    \n",
    "    # Get predicted bboxes\n",
    "    det_box, det_scores, det_cls = get_detections(img_filename)\n",
    "        \n",
    "    # Get ground truth bboxes\n",
    "    gt_box = gt_coords[(gt_chips == img_filename).flatten()]\n",
    "    gt_cls = gt_classes[(gt_chips == img_filename)]\n",
    "    \n",
    "    print('%d detected boxes, %d ground truth boxes' % (len(det_box), len(gt_box)))\n",
    "    \n",
    "    per_class_data = {}\n",
    "    for i in gt_unique:\n",
    "        per_class_data[i] = {\n",
    "            'scores': [],\n",
    "            'rects': [],\n",
    "            'gt_rects': [],\n",
    "            'rects_matched': [],\n",
    "            'gt_rects_matched': [],\n",
    "        }\n",
    "    \n",
    "    # For each class, match predicted and GT bboxes\n",
    "    for i in gt_unique:\n",
    "        s = det_scores[det_cls == i] # scores for this class\n",
    "        ssort = np.argsort(s)[::-1] # sorted score indices\n",
    "        sorted_scores = s[ssort].tolist() # sorted scores\n",
    "\n",
    "        # bounding boxes for this class (gt and predicted)\n",
    "        gt_box_i_cls = gt_box[gt_cls == i].flatten().tolist()\n",
    "        det_box_i_cls = det_box[det_cls == i]\n",
    "        det_box_i_cls = det_box_i_cls[ssort].flatten().tolist()\n",
    "\n",
    "        # convert into Rectangle objects (has helper functions)\n",
    "        gt_rects, _, _ = convert_to_rectangle_list(gt_box_i_cls)\n",
    "        rects, _, small_indices = convert_to_rectangle_list(det_box_i_cls)\n",
    "\n",
    "        # match all Rectangles\n",
    "        matching = Matching(gt_rects, rects)\n",
    "        rects_matched, gt_matched = matching.greedy_match(iou_threshold) # Claire comment: returns two boolean lists\n",
    "              \n",
    "        tp_indices = [i for i in range(len(rects)) if rects_matched[i] == True] if len(rects_matched) > 0 else []\n",
    "        fp_indices = [i for i in range(len(rects)) if rects_matched[i] == False] if len(rects_matched) > 0 else []\n",
    "        fn_indices = [i for i in range(len(gt_rects)) if gt_matched[i] == False] if len(gt_matched) > 0 else []\n",
    "        \n",
    "        # Rectangles by match type\n",
    "        tp_rects = [rects[i] for i in tp_indices]\n",
    "        fp_rects = [rects[i] for i in fp_indices]\n",
    "        fn_rects = [gt_rects[i] for i in fn_indices]\n",
    "        \n",
    "        # Scores by match type\n",
    "        tp_scores = [sorted_scores[i] for i in tp_indices]\n",
    "        fp_scores = [sorted_scores[i] for i in fp_indices]\n",
    "                \n",
    "            \n",
    "        per_class_data[i] = {\n",
    "            'scores': sorted_scores,\n",
    "            'rects': rects,\n",
    "            'gt_rects': gt_rects,\n",
    "            'rects_matched': rects_matched,\n",
    "            'gt_rects_matched': gt_matched,\n",
    "            # Counts by match type\n",
    "            'num_tp': len(tp_rects),\n",
    "            'num_fp': len(fp_rects),\n",
    "            'num_fn': len(fn_rects),\n",
    "            # Rects by match type\n",
    "            'tp_rects': tp_rects,\n",
    "            'fp_rects': fp_rects,\n",
    "            'fn_rects': fn_rects,\n",
    "            # Scores by match type\n",
    "            'tp_scores': tp_scores,\n",
    "            'fp_scores': fp_scores,\n",
    "        }\n",
    "\n",
    "    return per_class_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4029 detected boxes, 1985 ground truth boxes\n"
     ]
    }
   ],
   "source": [
    "per_class_data = evaluate_one('886.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scores': [0.558536, 0.467016, 0.400027, 0.390104, 0.388396, 0.383982, 0.381459, 0.376618, 0.366816, 0.366602, 0.358498, 0.349187, 0.344561, 0.339413, 0.338652, 0.332373, 0.327078, 0.324892, 0.322354, 0.319129, 0.318486, 0.308683], 'rects': [<scoring.rectangle.Rectangle object at 0x7f7ffcbdd550>, <scoring.rectangle.Rectangle object at 0x7f7ffcbdd240>, <scoring.rectangle.Rectangle object at 0x7f7ffcbdd5f8>, <scoring.rectangle.Rectangle object at 0x7f7ffcbdd358>, <scoring.rectangle.Rectangle object at 0x7f7ffcbdd588>, <scoring.rectangle.Rectangle object at 0x7f7ffcbdd748>, <scoring.rectangle.Rectangle object at 0x7f7ffcbdd438>, <scoring.rectangle.Rectangle object at 0x7f7ffcbdd320>, <scoring.rectangle.Rectangle object at 0x7f7ffcbdd390>, <scoring.rectangle.Rectangle object at 0x7f7ffcbdd400>, <scoring.rectangle.Rectangle object at 0x7f7ffcbdd6a0>, <scoring.rectangle.Rectangle object at 0x7f7ffcbdd470>, <scoring.rectangle.Rectangle object at 0x7f7ffcbdd0b8>, <scoring.rectangle.Rectangle object at 0x7f7ffcbdd4a8>, <scoring.rectangle.Rectangle object at 0x7f7ffcbdd630>, <scoring.rectangle.Rectangle object at 0x7f7ffcbdd6d8>, <scoring.rectangle.Rectangle object at 0x7f7ffcbdd710>, <scoring.rectangle.Rectangle object at 0x7f7ffcbdda20>, <scoring.rectangle.Rectangle object at 0x7f7ffcbdd048>, <scoring.rectangle.Rectangle object at 0x7f7ffcbdd3c8>, <scoring.rectangle.Rectangle object at 0x7f7ffcbdd4e0>, <scoring.rectangle.Rectangle object at 0x7f7ffcbdd128>], 'gt_rects': [], 'rects_matched': [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False], 'gt_rects_matched': [], 'num_tp': 0, 'num_fp': 22, 'num_fn': 0, 'tp_rects': [], 'fp_rects': [<scoring.rectangle.Rectangle object at 0x7f7ffcbdd550>, <scoring.rectangle.Rectangle object at 0x7f7ffcbdd240>, <scoring.rectangle.Rectangle object at 0x7f7ffcbdd5f8>, <scoring.rectangle.Rectangle object at 0x7f7ffcbdd358>, <scoring.rectangle.Rectangle object at 0x7f7ffcbdd588>, <scoring.rectangle.Rectangle object at 0x7f7ffcbdd748>, <scoring.rectangle.Rectangle object at 0x7f7ffcbdd438>, <scoring.rectangle.Rectangle object at 0x7f7ffcbdd320>, <scoring.rectangle.Rectangle object at 0x7f7ffcbdd390>, <scoring.rectangle.Rectangle object at 0x7f7ffcbdd400>, <scoring.rectangle.Rectangle object at 0x7f7ffcbdd6a0>, <scoring.rectangle.Rectangle object at 0x7f7ffcbdd470>, <scoring.rectangle.Rectangle object at 0x7f7ffcbdd0b8>, <scoring.rectangle.Rectangle object at 0x7f7ffcbdd4a8>, <scoring.rectangle.Rectangle object at 0x7f7ffcbdd630>, <scoring.rectangle.Rectangle object at 0x7f7ffcbdd6d8>, <scoring.rectangle.Rectangle object at 0x7f7ffcbdd710>, <scoring.rectangle.Rectangle object at 0x7f7ffcbdda20>, <scoring.rectangle.Rectangle object at 0x7f7ffcbdd048>, <scoring.rectangle.Rectangle object at 0x7f7ffcbdd3c8>, <scoring.rectangle.Rectangle object at 0x7f7ffcbdd4e0>, <scoring.rectangle.Rectangle object at 0x7f7ffcbdd128>], 'fn_rects': [], 'tp_scores': [], 'fp_scores': [0.558536, 0.467016, 0.400027, 0.390104, 0.388396, 0.383982, 0.381459, 0.376618, 0.366816, 0.366602, 0.358498, 0.349187, 0.344561, 0.339413, 0.338652, 0.332373, 0.327078, 0.324892, 0.322354, 0.319129, 0.318486, 0.308683]}\n"
     ]
    }
   ],
   "source": [
    "print(per_class_data[17])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw true positives, false positives, false negatives on img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bboxes(img_filename, per_class_data):\n",
    "    img_path = '../../xview_data/one_test_image/' + img_filename\n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "    output_path = 'bboxes/' + img_filename\n",
    "    \n",
    "    # Draw bounding boxes and labels of detections\n",
    "    for c in per_class_data:\n",
    "        class_name = class_num_to_name[c] if c in class_num_to_name else 'Unknown'\n",
    "        data = per_class_data[c]\n",
    "#         print('%s' % (class_name))\n",
    "        \n",
    "        # True positives\n",
    "        color = [0, 255, 0]\n",
    "        tp_scores = data['tp_scores']\n",
    "#         print('\\tTrue positives: %d' % (data['num_tp']))\n",
    "        for i, rect in enumerate(data['tp_rects']):\n",
    "            xmin, ymin, xmax, ymax = rect.coords\n",
    "            x1, y1, x2, y2 = max(xmin, 0), max(ymin, 0), max(xmax, 0), max(ymax, 0)\n",
    "            label = '%s %.2f' % (class_name, tp_scores[i])\n",
    "            plot_one_box([x1, y1, x2, y2], img, label=label, color=color, line_thickness=1)\n",
    "        \n",
    "#         False positives\n",
    "        color = [0, 0, 255]\n",
    "        fp_scores = data['fp_scores']\n",
    "#         print('\\tFalse positives: %d' % (data['num_fp']))\n",
    "        for i, rect in enumerate(data['fp_rects']):\n",
    "            xmin, ymin, xmax, ymax = rect.coords\n",
    "            x1, y1, x2, y2 = max(xmin, 0), max(ymin, 0), max(xmax, 0), max(ymax, 0)\n",
    "            label = '%s %.2f' % (class_name, fp_scores[i])\n",
    "            plot_one_box([x1, y1, x2, y2], img, label=label, color=color, line_thickness=1)\n",
    "    \n",
    "        # False negatives\n",
    "        color = [255, 0, 0]\n",
    "#         print('\\tFalse negatives: %d' % (data['num_fn']))\n",
    "        for rect in data['fn_rects']:\n",
    "            xmin, ymin, xmax, ymax = rect.coords\n",
    "            x1, y1, x2, y2 = max(xmin, 0), max(ymin, 0), max(xmax, 0), max(ymax, 0)\n",
    "            plot_one_box([x1, y1, x2, y2], img, label=class_name, color=color, line_thickness=1)\n",
    "        \n",
    "    cv2.imwrite(output_path.replace('.tif', '.jpg'), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bboxes('886.tif', per_class_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run for all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cde9f6ca9c34570a09edf419d59b620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=86), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168 detected boxes, 36 ground truth boxes\n",
      "1002 detected boxes, 522 ground truth boxes\n",
      "78 detected boxes, 7 ground truth boxes\n",
      "46 detected boxes, 19 ground truth boxes\n",
      "69 detected boxes, 138 ground truth boxes\n",
      "48 detected boxes, 43 ground truth boxes\n",
      "1892 detected boxes, 795 ground truth boxes\n",
      "4 detected boxes, 1 ground truth boxes\n",
      "23 detected boxes, 10 ground truth boxes\n",
      "25 detected boxes, 14 ground truth boxes\n",
      "1003 detected boxes, 351 ground truth boxes\n",
      "38642 detected boxes, 827 ground truth boxes\n",
      "369 detected boxes, 279 ground truth boxes\n",
      "241 detected boxes, 44 ground truth boxes\n",
      "75 detected boxes, 1 ground truth boxes\n",
      "4 detected boxes, 2 ground truth boxes\n",
      "20 detected boxes, 7 ground truth boxes\n",
      "845 detected boxes, 488 ground truth boxes\n",
      "49 detected boxes, 14 ground truth boxes\n",
      "488 detected boxes, 302 ground truth boxes\n",
      "262 detected boxes, 172 ground truth boxes\n",
      "5234 detected boxes, 5346 ground truth boxes\n",
      "392 detected boxes, 227 ground truth boxes\n",
      "5159 detected boxes, 2855 ground truth boxes\n",
      "952 detected boxes, 615 ground truth boxes\n",
      "6074 detected boxes, 2971 ground truth boxes\n",
      "361 detected boxes, 105 ground truth boxes\n",
      "23 detected boxes, 32 ground truth boxes\n",
      "3 detected boxes, 4 ground truth boxes\n",
      "14 detected boxes, 1 ground truth boxes\n",
      "2436 detected boxes, 183 ground truth boxes\n",
      "36 detected boxes, 33 ground truth boxes\n",
      "88 detected boxes, 58 ground truth boxes\n",
      "316 detected boxes, 148 ground truth boxes\n",
      "32 detected boxes, 12 ground truth boxes\n",
      "16 detected boxes, 8 ground truth boxes\n",
      "1329 detected boxes, 1020 ground truth boxes\n",
      "1200 detected boxes, 900 ground truth boxes\n",
      "1074 detected boxes, 966 ground truth boxes\n",
      "205 detected boxes, 49 ground truth boxes\n",
      "36 detected boxes, 36 ground truth boxes\n",
      "204 detected boxes, 29 ground truth boxes\n",
      "9 detected boxes, 4 ground truth boxes\n",
      "615 detected boxes, 297 ground truth boxes\n",
      "13 detected boxes, 14 ground truth boxes\n",
      "35 detected boxes, 21 ground truth boxes\n",
      "24 detected boxes, 21 ground truth boxes\n",
      "7 detected boxes, 2 ground truth boxes\n",
      "311 detected boxes, 299 ground truth boxes\n",
      "35 detected boxes, 22 ground truth boxes\n",
      "6868 detected boxes, 2338 ground truth boxes\n",
      "3 detected boxes, 1 ground truth boxes\n",
      "65 detected boxes, 42 ground truth boxes\n",
      "796 detected boxes, 817 ground truth boxes\n",
      "470 detected boxes, 133 ground truth boxes\n",
      "75 detected boxes, 41 ground truth boxes\n",
      "115 detected boxes, 19 ground truth boxes\n",
      "103 detected boxes, 52 ground truth boxes\n",
      "1610 detected boxes, 1010 ground truth boxes\n",
      "500 detected boxes, 113 ground truth boxes\n",
      "4527 detected boxes, 2813 ground truth boxes\n",
      "1176 detected boxes, 553 ground truth boxes\n",
      "4 detected boxes, 43 ground truth boxes\n",
      "13 detected boxes, 2 ground truth boxes\n",
      "3491 detected boxes, 2030 ground truth boxes\n",
      "174 detected boxes, 124 ground truth boxes\n",
      "1443 detected boxes, 608 ground truth boxes\n",
      "295 detected boxes, 185 ground truth boxes\n",
      "468 detected boxes, 325 ground truth boxes\n",
      "4615 detected boxes, 2134 ground truth boxes\n",
      "3 detected boxes, 1 ground truth boxes\n",
      "3261 detected boxes, 2213 ground truth boxes\n",
      "395 detected boxes, 249 ground truth boxes\n",
      "246 detected boxes, 135 ground truth boxes\n",
      "141 detected boxes, 60 ground truth boxes\n",
      "508 detected boxes, 261 ground truth boxes\n",
      "2376 detected boxes, 1456 ground truth boxes\n",
      "9478 detected boxes, 3674 ground truth boxes\n",
      "3173 detected boxes, 2457 ground truth boxes\n",
      "1498 detected boxes, 676 ground truth boxes\n",
      "1 detected boxes, 2 ground truth boxes\n",
      "1409 detected boxes, 555 ground truth boxes\n",
      "986 detected boxes, 462 ground truth boxes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_imgs = os.listdir('../../xview_data/test_images')\n",
    "\n",
    "all_data = {}\n",
    "for file in tqdm(test_imgs):\n",
    "    if not file.endswith('.tif'):\n",
    "        continue\n",
    "        \n",
    "    if not os.path.exists('./' + output_folder + '/' + file + '.txt'):\n",
    "        continue\n",
    "        \n",
    "    per_class_data = evaluate_one(file)\n",
    "    plot_bboxes(file, per_class_data)\n",
    "    all_data[file] = per_class_data\n",
    "    \n",
    "pickle.dump(all_data, open('test_evaluation' + suffix + '.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pickle.load(open('test_evaluation' + suffix + '.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71157922a93542d58162f736f41b76cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=83), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Write to csv\n",
    "with open('test_evaluation' + suffix + '.csv', mode='w') as file:\n",
    "    file_writer = csv.writer(file, delimiter=',')\n",
    "    \n",
    "    for img in tqdm(test_data):\n",
    "        for c in test_data[img]:\n",
    "            class_name = class_num_to_name[c] if c in class_num_to_name else 'Unknown'\n",
    "            data = test_data[img][c]\n",
    "            \n",
    "            tp_scores = data['tp_scores']\n",
    "            for i, rect in enumerate(data['tp_rects']):\n",
    "                file_writer.writerow([\n",
    "                    img,\n",
    "                    class_name,\n",
    "                    rect.area(),\n",
    "                    'tp',\n",
    "                    tp_scores[i]\n",
    "                ])\n",
    "                \n",
    "            fp_scores = data['fp_scores']\n",
    "            for i, rect in enumerate(data['fp_rects']):\n",
    "                file_writer.writerow([\n",
    "                    img,\n",
    "                    class_name,\n",
    "                    rect.area(),\n",
    "                    'fp',\n",
    "                    fp_scores[i]\n",
    "                ])\n",
    "                \n",
    "            for i, rect in enumerate(data['fn_rects']):\n",
    "                file_writer.writerow([\n",
    "                    img,\n",
    "                    class_name,\n",
    "                    rect.area(),\n",
    "                    'fn',\n",
    "                    0\n",
    "                ])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    }
   ],
   "source": [
    "total_num_gt = 0\n",
    "\n",
    "for c in test_data['1799.tif']:\n",
    "    data = test_data['1799.tif'][c]\n",
    "#     print('%d: %d == %d + %d' % (c, len(data['gt_rects']), data['num_tp'], data['num_fn']))\n",
    "    assert(len(data['gt_rects']) == data['num_tp'] + data['num_fn'])\n",
    "    total_num_gt += len(data['gt_rects'])\n",
    "    \n",
    "print(total_num_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Darknet\n",
    "import torch\n",
    "\n",
    "cuda = True\n",
    "device = torch.device('cuda:0' if cuda else 'cpu')\n",
    "\n",
    "model = Darknet('cfg/c60_a30symmetric.cfg', 800)\n",
    "checkpoint = torch.load('weights/weights_30_original.pt', map_location='cpu')\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "model.to(device).eval()\n",
    "del checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import build_targets\n",
    "\n",
    "def evaluate_one_utils(img_filename):\n",
    "    # Get predicted bboxes\n",
    "    det_box, det_scores, det_cls = get_detections(img_filename)\n",
    "    # Get ground truth bboxes\n",
    "    gt_box = gt_coords[(gt_chips == img_filename).flatten()]\n",
    "    gt_cls = gt_classes[(gt_chips == img_filename)]\n",
    "    \n",
    "    nA = 3\n",
    "    nC = 60\n",
    "    anchor_wh = model.scaled_anchors\n",
    "    nGT, nCorrect, tx, ty, tw, th, tconf, tcls = build_targets(det_box, det_conf, det_cls, target, anchor_wh, nA, nC, nG, requestPrecision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Darknet' object has no attribute 'scaled_anchors'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-240cebdf67af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate_one_utils\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1184.tif'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-4caa818c2d56>\u001b[0m in \u001b[0;36mevaluate_one_utils\u001b[0;34m(img_filename)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mnA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mnC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0manchor_wh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaled_anchors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mnGT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnCorrect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtconf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdet_box\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdet_conf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdet_cls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manchor_wh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequestPrecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    533\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 535\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Darknet' object has no attribute 'scaled_anchors'"
     ]
    }
   ],
   "source": [
    "evaluate_one_utils('1184.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('bboxes.csv', 'w') as file:\n",
    "    writer = csv.writer(file, delimiter=',')\n",
    "    for i in range(len(gt_coords)):\n",
    "        x1, y1, x2, y2 = gt_coords[i]\n",
    "        width = x2 - x1\n",
    "        height = y2 - y1\n",
    "        writer.writerow([width, height])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
